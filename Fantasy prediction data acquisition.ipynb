{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "driver_filepath = r\"C:\\Users\\Jim\\Downloads\\chromedriver_win32/chromedriver.exe\"\n",
    "save_to_file = True\n",
    "folder_to_save_to = r\"C:\\Users\\Jim\\Documents\\fantasy prediction/\"\n",
    "\n",
    "#Import all neccessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from selenium import webdriver\n",
    "import urllib.request\n",
    "import json\n",
    "import urllib\n",
    "import re\n",
    "import requests\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from itertools import product\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a fuzzy merge function\n",
    "def fuzzy_merge(df_1, df_2, key1, key2, threshold=90, limit=1):\n",
    "    \"\"\"\n",
    "    :param df_1: the left table to join\n",
    "    :param df_2: the right table to join\n",
    "    :param key1: key column of the left table\n",
    "    :param key2: key column of the right table\n",
    "    :param threshold: how close the matches should be to return a match, based on Levenshtein distance\n",
    "    :param limit: the amount of matches that will get returned, these are sorted high to low\n",
    "    :return: dataframe with boths keys and matches\n",
    "    \"\"\"\n",
    "    s = df_2[key2].tolist()\n",
    "\n",
    "    m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))    \n",
    "    df_1['matches'] = m\n",
    "\n",
    "    m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n",
    "    df_1['matches'] = m2\n",
    "\n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of fpl player names and ids: players_df\n",
    "fpl_url = 'https://fantasy.premierleague.com/api/bootstrap-static/'\n",
    "response=requests.get(fpl_url)\n",
    "fpl_response = json.loads(response.content)\n",
    "\n",
    "players = fpl_response['elements']\n",
    "players_df_whole = pd.DataFrame.from_dict(players)\n",
    "players_df = players_df_whole[['team', 'web_name', 'id', 'chance_of_playing_next_round','now_cost', 'minutes', 'first_name', 'second_name']]\n",
    "players_df.dropna()\n",
    "\n",
    "teams = fpl_response['teams']\n",
    "teams_df_whole = pd.DataFrame.from_dict(teams)\n",
    "teams_df = teams_df_whole[['name', 'id']]\n",
    "players_df = pd.merge(players_df, teams_df, how='left', left_on = ['team'], right_on = ['id'])\n",
    "players_df['team_name'] = players_df['name']\n",
    "players_df = players_df[['team', 'web_name', 'id_x', 'chance_of_playing_next_round','now_cost', 'minutes', 'team_name', 'first_name', 'second_name']]\n",
    "players_df['full_name'] = players_df['first_name'] + players_df['second_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no completed match data found\n"
     ]
    }
   ],
   "source": [
    "#Get this season's odds data: odds_data\n",
    "driver = webdriver.Chrome(driver_filepath)\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(r\"https://www.oddsportal.com/soccer/england/premier-league/results/\")\n",
    "c_odds_df=pd.read_html(driver.find_element_by_id(\"tournamentTable\").get_attribute(\"outerHTML\"))\n",
    "c_odds_df=c_odds_df[0]\n",
    "if len(c_odds_df) != 1:\n",
    "    c_odds_df.columns = c_odds_df.columns.droplevel(0)\n",
    "    c_odds_df.columns = ['1', '2', '3', '4', '5', '6', '7']       \n",
    "\n",
    "    for i in range(2, 9):\n",
    "        url = r\"https://www.oddsportal.com/soccer/england/premier-league/results/#/page/\" + str(i) + r\"/\"\n",
    "        driver = webdriver.Chrome(driver_filepath)\n",
    "        driver.implicitly_wait(30)\n",
    "        driver.get(url)\n",
    "        tempdf=pd.read_html(driver.find_element_by_id(\"tournamentTable\").get_attribute(\"outerHTML\"))\n",
    "        tempdf=tempdf[0]\n",
    "        tempdf.columns = tempdf.columns.droplevel(0)\n",
    "        tempdf.columns = ['1', '2', '3', '4', '5', '6', '7']\n",
    "        c_odds_df = c_odds_df.append(tempdf, ignore_index = True)\n",
    "else:\n",
    "    print(\"no completed match data found\")\n",
    "driver = webdriver.Chrome(driver_filepath)\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(r\"https://www.oddsportal.com/soccer/england/premier-league/\")\n",
    "tempdf=pd.read_html(driver.find_element_by_id(\"tournamentTable\").get_attribute(\"outerHTML\"))\n",
    "tempdf=tempdf[0]\n",
    "if len(tempdf) != 1:\n",
    "    tempdf.columns = tempdf.columns.droplevel(0)\n",
    "    tempdf.columns = ['1', '2', '3', '4', '5', '6', '7']\n",
    "    c_odds_df = c_odds_df.append(tempdf, ignore_index = True)\n",
    "else: \n",
    "    print(\"no fixture data found\")\n",
    "c_odds_df = c_odds_df[c_odds_df[\"6\"].str.contains(\"/\", na= False)]\n",
    "odds_data = pd.DataFrame(c_odds_df[\"2\"].str.split(' - ',1).tolist(), columns = ['home_team','away_team'])\n",
    "split_df_1 = pd.DataFrame(c_odds_df[\"4\"].str.split('/',1).tolist(), columns = ['last','first'])\n",
    "split_df_1[\"first\"] = pd.to_numeric(split_df_1[\"first\"])\n",
    "split_df_1[\"last\"] = pd.to_numeric(split_df_1[\"last\"])\n",
    "odds_data[\"home_odds\"] = split_df_1[\"first\"]/split_df_1[\"last\"]\n",
    "split_df_2 = pd.DataFrame(c_odds_df[\"6\"].str.split('/',1).tolist(), columns = ['last','first'])\n",
    "split_df_2[\"first\"] = pd.to_numeric(split_df_2[\"first\"])\n",
    "split_df_2[\"last\"] = pd.to_numeric(split_df_2[\"last\"])\n",
    "odds_data[\"away_odds\"] = split_df_2[\"first\"]/split_df_2[\"last\"]\n",
    "odds_data = odds_data.replace({'Tottenham':'Spurs'}, regex=True)\n",
    "if save_to_file == True:\n",
    "    odds_data.to_csv((folder_to_save_to + \"odds_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-6b9c0d9c8ad7>, line 38)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-6b9c0d9c8ad7>\"\u001b[1;36m, line \u001b[1;32m38\u001b[0m\n\u001b[1;33m    s_odds_data.to_csv(filepath)\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#get odds data for past seasons, season format \"yyyy-yyyy\"\n",
    "past_seasons = [\"2019-2020\", \"2018-2019\", \"2017-2018\", \"2016-2017\"]\n",
    "\n",
    "for season in past_seasons:\n",
    "    driver = webdriver.Chrome(driver_filepath)\n",
    "    driver.implicitly_wait(30)\n",
    "    driver.get(r\"https://www.oddsportal.com/soccer/england/premier-league-\" + season +\"/results/\")\n",
    "    seasons=pd.read_html(driver.find_element_by_id(\"tournamentTable\").get_attribute(\"outerHTML\"))\n",
    "    seasons=seasons[0]\n",
    "    seasons.columns = seasons.columns.droplevel(0)\n",
    "    seasons.columns = ['1', '2', '3', '4', '5', '6', '7']       \n",
    "\n",
    "    for i in range(2, 9):\n",
    "        url = r\"https://www.oddsportal.com/soccer/england/premier-league-\" + season + \"/results/#/page/\" + str(i) + r\"/\"\n",
    "        driver = webdriver.Chrome(driver_filepath)\n",
    "        driver.implicitly_wait(30)\n",
    "        driver.get(url)\n",
    "        tempdf=pd.read_html(driver.find_element_by_id(\"tournamentTable\").get_attribute(\"outerHTML\"))\n",
    "        tempdf=tempdf[0]\n",
    "        tempdf.columns = tempdf.columns.droplevel(0)\n",
    "        tempdf.columns = ['1', '2', '3', '4', '5', '6', '7']\n",
    "        seasons = seasons.append(tempdf, ignore_index = True)\n",
    "\n",
    "    \n",
    "        seasons = seasons[seasons[\"6\"].str.contains(\"/\", na= False)]\n",
    "        s_odds_data = pd.DataFrame(seasons[\"2\"].str.split(' - ',1).tolist(), columns = ['home_team','away_team'])\n",
    "        split_df_1 = pd.DataFrame(seasons[\"4\"].str.split('/',1).tolist(), columns = ['last','first'])\n",
    "        split_df_1[\"first\"] = pd.to_numeric(split_df_1[\"first\"])\n",
    "        split_df_1[\"last\"] = pd.to_numeric(split_df_1[\"last\"])\n",
    "        s_odds_data[\"home_odds\"] = split_df_1[\"first\"]/split_df_1[\"last\"]\n",
    "        split_df_2 = pd.DataFrame(seasons[\"6\"].str.split('/',1).tolist(), columns = ['last','first'])\n",
    "        split_df_2[\"first\"] = pd.to_numeric(split_df_2[\"first\"])\n",
    "        split_df_2[\"last\"] = pd.to_numeric(split_df_2[\"last\"])\n",
    "        s_odds_data[\"away_odds\"] = split_df_2[\"first\"]/split_df_2[\"last\"]\n",
    "        s_odds_data = s_odds_data.replace({'Tottenham':'Spurs'}, regex=True)\n",
    "    if save_to_file == True:\n",
    "        filepath = (folder_to_save_to + \"odds_data_\" + season +\".csv\"\n",
    "        s_odds_data.to_csv(filepath)\n",
    "    else:\n",
    "        odds_data.append(s_odds_data, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get links for historic fpl data from github, past season format \"yyyy-yy\"\n",
    "github_past_seasons = ['2019-20','2016-17', '2017-18', '2018-19']\n",
    "players = []\n",
    "links = []\n",
    "season_ = []\n",
    "for season in github_past_seasons:\n",
    "    github_url = \"https://github.com/vaastav/Fantasy-Premier-League/tree/master/data/\" +str(season) + \"/players\"\n",
    "    github_data = requests.get(github_url)\n",
    "    soup = BeautifulSoup(github_data.text)\n",
    "    soup = soup.findAll(\"a\", {\"class\" : \"js-navigation-open link-gray-dark\"})\n",
    "    for link in soup:\n",
    "        players.append(link.get(\"title\"))\n",
    "        links.append(link.get(\"href\"))\n",
    "        season_.append(season)\n",
    "\n",
    "links_dataframe = pd.DataFrame(players, columns=['name'])\n",
    "links_dataframe['link'] = pd.DataFrame(links, columns = ['link'])['link']\n",
    "links_dataframe['season'] = pd.DataFrame(season_, columns=['season'])['season']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to split into all past seasons here\n",
    "links_dataframe_201617 = links_dataframe[links_dataframe['season'] == \"2016-17\"]\n",
    "links_dataframe_201718 = links_dataframe[links_dataframe['season'] == \"2017-18\"]\n",
    "links_dataframe_201819 = links_dataframe[links_dataframe['season'] == \"2018-19\"]\n",
    "links_dataframe_201920 = links_dataframe[links_dataframe['season'] == \"2019-20\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following operations are done individually because of my PC's RAM constraints\n",
    "players_merge_201819 = fuzzy_merge(players_df, links_dataframe_201819, 'full_name', 'name', threshold = 55, limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_merge_201819 = players_merge_201819[players_merge_201819['matches'] != \"\"]\n",
    "players_merge_201819['matches'].astype(str)\n",
    "links_dataframe_201819['name'].astype(str)\n",
    "players_links_201819 = players_merge_201819.merge(links_dataframe_201819, how = 'left', left_on = 'matches', right_on = 'name')\n",
    "players_links_201819['fuzz_ratio'] = players_links_201819.apply(lambda x: fuzz.partial_ratio(x['full_name'], x['matches']), axis=1)\n",
    "players_links_201819 = players_links_201819[players_links_201819['fuzz_ratio'] > 80]\n",
    "if save_to_file == True:\n",
    "    players_links_201819.to_csv((folder_to_save_to + \"players_links_2018-19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_merge_201718 = fuzzy_merge(players_df, links_dataframe_201718, 'full_name', 'name', threshold = 55, limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_merge_201718 = players_merge_201718[players_merge_201718['matches'] != \"\"]\n",
    "players_merge_201718['matches'].astype(str)\n",
    "links_dataframe_201718['name'].astype(str)\n",
    "players_links_201718 = players_merge_201718.merge(links_dataframe_201718, how = 'left', left_on = 'matches', right_on = 'name')\n",
    "players_links_201718['fuzz_ratio'] = players_links_201718.apply(lambda x: fuzz.partial_ratio(x['full_name'], x['matches']), axis=1)\n",
    "players_links_201718 = players_links_201718[players_links_201718['fuzz_ratio'] > 80]\n",
    "if save_to_file == True:\n",
    "    players_links_201718.to_csv((folder_to_save_to + \"players_links_2017-18.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_merge_201617 = fuzzy_merge(players_df, links_dataframe_201617, 'full_name', 'name', threshold = 55, limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_merge_201617 = players_merge_201617[players_merge_201617['matches'] != \"\"]\n",
    "players_merge_201617['matches'].astype(str)\n",
    "links_dataframe_201617['name'].astype(str)\n",
    "players_links_201617 = players_merge_201617.merge(links_dataframe_201617, how = 'left', left_on = 'matches', right_on = 'name')\n",
    "players_links_201617['fuzz_ratio'] = players_links_201617.apply(lambda x: fuzz.partial_ratio(x['full_name'], x['matches']), axis=1)\n",
    "players_links_201617 = players_links_201617[players_links_201617['fuzz_ratio'] > 80]\n",
    "if save_to_file == True:\n",
    "    players_links_201617.to_csv((folder_to_save_to + \"players_links_2016-17.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_merge_201920 = fuzzy_merge(players_df, links_dataframe_201920, 'full_name', 'name', threshold = 55, limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_merge_201920 = players_merge_201920[players_merge_201920['matches'] != \"\"]\n",
    "players_merge_201920['matches'].astype(str)\n",
    "links_dataframe_201920['name'].astype(str)\n",
    "players_links_201920 = players_merge_201920.merge(links_dataframe_201920, how = 'left', left_on = 'matches', right_on = 'name')\n",
    "players_links_201920['fuzz_ratio'] = players_links_201920.apply(lambda x: fuzz.partial_ratio(x['full_name'], x['matches']), axis=1)\n",
    "players_links_201920 = players_links_201920[players_links_201920['fuzz_ratio'] > 80]\n",
    "if save_to_file == True:\n",
    "    players_links_201920.to_csv((folder_to_save_to + \"players_links_2019-20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the odds website loads differently on different machines - requires tailoring\n",
    "#this formatting was neccessary on my laptop\n",
    "    #replaces code in cell 4\n",
    "    c_odds_df = c_odds_df[c_odds_df[\"2\"].str.contains(\"-\", na= False)]\n",
    "    odds_data = pd.DataFrame(c_odds_df[\"2\"].str.split(' - ',1).tolist(), columns = ['home_team','away_team'])\n",
    "    c_odds_df = c_odds_df.reset_index()\n",
    "    odds_data['home_odds'] = 1/c_odds_df[\"4\"]\n",
    "    odds_data['away_odds'] = 1/c_odds_df[\"6\"]\n",
    "    \n",
    "    #replaces code in cell 5\n",
    "    seasons = seasons[seasons[\"2\"].str.contains(\"-\", na= False)]\n",
    "    odds_data = pd.DataFrame(seasons[\"2\"].str.split(' - ',1).tolist(), columns = ['home_team','away_team'])\n",
    "    seasons = seasons.reset_index()\n",
    "    odds_data['home_odds'] = 1/seasons[\"4\"]\n",
    "    odds_data['away_odds'] = 1/seasons[\"6\"]\n",
    "    odds_data = odds_data.replace({'Tottenham':'Spurs'}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
